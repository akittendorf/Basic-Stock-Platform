{"cells":[{"cell_type":"markdown","source":["# Consumer Databrick for Finance Group:\nContributors: yvcvs, akittendorf, dbode777, TKorby"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"475e3217-b75d-461b-8068-38c706f134e2"}}},{"cell_type":"markdown","source":["## Module Imports"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3d822731-d319-4a7b-90e0-62704ece67f6"}}},{"cell_type":"code","source":["from time import sleep\nimport json\nimport uuid\nimport datetime\nfrom confluent_kafka import Consumer, KafkaError, KafkaException\nimport pandas as pd\nimport numpy as np\nfrom sklearn.impute import SimpleImputer"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"56f3627f-f1e7-4155-a569-1603a1c24ab0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Error Handling Functions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a231af05-5790-498e-8286-c5282b3f1d30"}}},{"cell_type":"code","source":["def error_cb(err):\n    \"\"\" The error callback is used for generic client errors. These\n        errors are generally to be considered informational as the client will\n        automatically try to recover from all errors, and no extra action\n        is typically required by the application.\n        For this example however, we terminate the application if the client\n        is unable to connect to any broker (_ALL_BROKERS_DOWN) and on\n        authentication errors (_AUTHENTICATION). \"\"\"\n\n    print(\"Client error: {}\".format(err))\n    if err.code() == KafkaError._ALL_BROKERS_DOWN or \\\n       err.code() == KafkaError._AUTHENTICATION:\n        # Any exception raised from this callback will be re-raised from the\n        # triggering flush() or poll() call.\n        raise KafkaException(err)\n        \ndef msg_reader(some_list, msg):\n    \"\"\"\n    A Kafka message reader that takes in a message as msg and a list to store the messages in. If the message is not None, the contents of the message, \n    as well as a timestamp of when the message was retrieved, are appended to the list parameter as a JSON object.\n    If the message contains an error, the error for that message is printed out.\n    This function only works inside of a while loop.\n    \"\"\"\n    if msg is None:\n        return False\n    elif msg.error():\n        print(f\"Consumer error: {msg.error()}\")\n        return False\n    else:\n        rows = json.loads(f\"{msg.value().decode('utf-8')}\")\n        rows['timestamp'] = msg.timestamp()[1]\n        some_list.append(rows)\n        return True"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de01bf17-54c1-4d1b-90c1-7a750f918f4a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["# Consumer - Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8c6da5f9-3d5f-4609-acca-d45f7db52526"}}},{"cell_type":"code","source":["# ask tom if all of these confluent variables need to be hidden -Amy 2/5/22\nconfluentClusterName = \"stage3talent\"\nconfluentBootstrapServers = \"pkc-ldvmy.centralus.azure.confluent.cloud:9092\"\nconfluentTopicName = \"sfb-blob\"\nschemaRegistryUrl = \"https://psrc-gq7pv.westus2.azure.confluent.cloud\"\n\nconfluentApiKey = dbutils.secrets.get(scope = 'sfb_blob', key = 'mario') # Insert Confluent API Key Here\nconfluentSecret = dbutils.secrets.get(scope = 'sfb_blob', key = 'fawful') # Insert Confluent Secret Here\nconfluentRegistryApiKey = dbutils.secrets.get(scope = 'sfb_blob', key = 'luigi') # Insert Confluent Registry Key Here\nconfluentRegistrySecret = dbutils.secrets.get(scope = 'sfb_blob', key = 'peach') # Insert Confluent Registry Secret Here"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"493e3020-023c-4a87-8d2b-89e74f80d741"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["#Kakfa Class Setup.\nc = Consumer({\n    'bootstrap.servers': confluentBootstrapServers,\n    'sasl.mechanism': 'PLAIN',\n    'security.protocol': 'SASL_SSL',\n    'sasl.username': confluentApiKey,\n    'sasl.password': confluentSecret,\n    'group.id': str(uuid.uuid1()),  # this will create a new consumer group on each invocation.\n    'auto.offset.reset': 'earliest',\n    'enable.auto.commit': True,\n    'error_cb': error_cb,\n})\n\nc.subscribe(['sfb-blob'])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"43dd5c2c-dad9-438b-ab9a-92ca28b289ed"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["clientSecret = dbutils.secrets.get(scope = 'sfb_blob', key = 'bowser')\nclientid = dbutils.secrets.get(scope = 'sfb_blob', key = 'yoshi') \n\nstorageAccount = \"gen10datafund2111\"\nstorageContainer = \"superfinancebros\"\nmount_point = \"/mnt/superfinancebros/capstone\"\n\n# Configuration for mount point\nconfigs = {\"fs.azure.account.auth.type\": \"OAuth\",\n       \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n       \"fs.azure.account.oauth2.client.id\": clientid,\n       \"fs.azure.account.oauth2.client.secret\": clientSecret,\n       \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/d46b54b2-a652-420b-aa5a-2ef7f8fc706e/oauth2/token\",\n       \"fs.azure.createRemoteFileSystemDuringInitialization\": \"true\"}\n\ntry: \n    dbutils.fs.unmount(mount_point)\nexcept:\n    pass\n\ndbutils.fs.mount(\nsource = \"abfss://\"+storageContainer+\"@\"+storageAccount+\".dfs.core.windows.net/\",\nmount_point = mount_point,\nextra_configs = configs)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7fe96c50-646a-4282-9137-4db4451b2b8e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/mnt/superfinancebros/capstone has been unmounted.\nOut[48]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/mnt/superfinancebros/capstone has been unmounted.\nOut[48]: True</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["ETF_stocks = ['VTI','VGT','VIS','VHT','VFH','VCR']\n\n# {\"name\": \"Real Gross Domestic Product\", \"interval\": \"annual\", \"unit\": \"billions of dollars\", \"data\": []}\nmessages = []\nwork = True\nwhile work:\n    try:\n        msg = c.poll(timeout=1.0)\n        work = msg_reader(messages, msg)\n    except Exception as e: # Outer except statement\n        print(e)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9a52b6f5-37ec-4ebb-87be-c3723545cd7a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["month_stock_info = []\neconomic_features = []\n\nfor message in messages:\n    if 'Meta Data' in message.keys():\n        month_stock_info.append(message)\n    else:\n        economic_features.append(message)\ntry:       \n    month_stock_info =  month_stock_info[-6:]\n    economic_features = economic_features[-7:]\nexcept Exception as e:\n    print(e)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"44832598-171b-4c57-be5f-7e95b3f92df5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Cleaning the Kafka Messages\n\nThis section will create all desired data frames that will be used for our ML model and for our visualizations. \n\nData frames created include:\n  - One that combines ETF stocks percentage change in closing prices with the economic features, condensed to a monthly time scale, and null values imputed with the averages for each feature.\n  - One that combines the closing prices of all ETF stocks and the US revenue data, condensed to an annual time scale. \n  \nThis should contain all the information needed for our visualizations."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cf94f693-f91d-4e25-800c-fd6376be26e6"}}},{"cell_type":"markdown","source":["### Annual Stock Price and US Revenue Cleaning"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7e9fe8a5-a2d1-4cb6-8924-03c8dd319b07"}}},{"cell_type":"code","source":["# Data Cleaning Steps for ETL\nimport numpy as np\nmean_fit = SimpleImputer(missing_values=np.nan,strategy='mean')\n\ntry:\n    stock_dict = {}\n    for stock in range(0,len(month_stock_info)):\n        new_dict = {}\n        for date in list(month_stock_info[stock]['Monthly Time Series'].keys()): #Looks at every date for a given stock\n            new_dict[date] = month_stock_info[stock]['Monthly Time Series'][date]['4. close'] # Saves the closing price for that date in a dictionary that has all closing prices a stock\n\n        # Saves the closing price dictionary to a key named after the stock (i.e. {'VTI': {'2022-01-01':'55', ...}, ...})\n        stock_dict[ETF_stocks[stock]] = new_dict\n\n    # Data Cleaning Steps for ETL\n    new_df = pd.DataFrame(stock_dict)\n\n    for x in list(new_df.columns):\n        new_df[x] = pd.to_numeric(new_df[x],downcast='float')\n\n# Impute null values in the event that the dates of recorded data aren't the same for each ETF stock\n    for column in list(new_df.columns):\n        new_df[column] = mean_fit.fit_transform(new_df[column].values.reshape(-1,1))\n\n    # Sorting the monthly data to be between the years 2006 and 2020\n    new_df['Year'] = list(map(lambda date: int(date[0:4]), list(new_df.index))) # Create year column to filter out years prior to 2006\n    new_df = new_df[(2005<new_df['Year']) & (new_df['Year']<=2020)]\n    new_df['Year'] = pd.to_numeric(new_df['Year'],downcast='integer')\n\n    # Grouping by year and merging the US census data with the annual stock prices\n    annual_df = new_df.groupby('Year').mean()\n    annual_df['Year'] = list(annual_df.index)\n    annual_df.rename_axis('',axis=0,inplace=True)\n\n    US_rev = pd.read_csv(f\"/dbfs{mount_point}/USrevenue.csv\")\n    US_rev['Year'] = pd.to_numeric(US_rev['Year'])\n    annual_df['US_rev'] = US_rev['United States'].values # Ready to load into SQL\n\n    #Save data to blob container as a backup file\n    annual_df.to_json(f\"/dbfs{mount_point}/Cleaned_Dataframes/annual_data.json\")\n    \nexcept Exception as e:\n    print(e)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c7dd2c9d-bbaa-4850-ad23-6a34054f5834"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Monthly Stock Price Cleaning\n\nCombines economic feature data with pct_change data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"648c469d-cd97-4afc-85e5-4d6ad9dd1f51"}}},{"cell_type":"code","source":["# Data Cleaning Steps for ETL\ntry:\n    df = pd.DataFrame(month_stock_info[0]['Monthly Time Series'])\n    df = df.T\n    for x in range(0, len(list(df.columns))):\n        df.rename({df.columns[x] : df.columns[x][3:]},axis='columns',inplace=True)\n\n    for x in list(df.columns):\n        df[x] = pd.to_numeric(df[x],downcast='float')\n        \n    copy_df = df.copy()\n    # set index dates\n    # create series of VTI dates\n    vtiDates = pd.Series(copy_df.index)\n    vtiDates = vtiDates.apply(lambda date: datetime.date(int(date[0:4]),int(date[5:7]),1))\n\n    # set index\n    copy_df.set_index(vtiDates, inplace=True)\n\n    for x in range(0,len(economic_features)):\n        dates = map(lambda date: date['date'][:7], economic_features[x]['data'])\n        values = map(lambda value: value['value'], economic_features[x]['data'])\n        \n        indicator = pd.DataFrame(values,index=dates,columns=[economic_features[x]['name']])\n        indicator.replace('.',np.nan,inplace=True) #Replacing . entries with null values for imputation later\n\n        # format the date index\n        # create series of inidcator dates\n        indicatorDates = pd.Series(indicator.index)\n        indicatorDates = indicatorDates.apply(lambda date: datetime.date(int(date[0:4]),int(date[5:7]),1))\n\n        # set index to be dates\n        indicator.set_index(indicatorDates, inplace=True)\n\n        indicator[economic_features[x]['name']] = pd.to_numeric(indicator[economic_features[x]['name']])\n        copy_df = copy_df.join(indicator, how='outer')\n        \n    copy_df['Year'] = list(map(lambda date: int(str(date)[0:4]),copy_df.index)) # Create year column to filter out years prior to 2006\n    modern_df = copy_df[copy_df['Year']>2005]\n    \n    # Impute null values with the averages for each column\n    for column in list(modern_df.columns):\n        modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n    \n# Merges the percentage change of all ETF stocks to modern_df\n    monthly_df = pd.DataFrame(stock_dict)\n    indicatorDates = pd.Series(monthly_df.index)\n    indicatorDates = indicatorDates.apply(lambda date: datetime.date(int(date[0:4]),int(date[5:7]),1))\n\n    # set index to be dates\n    monthly_df.set_index(indicatorDates, inplace=True)\n\n    for x in list(monthly_df.columns):\n        monthly_df[x] = pd.to_numeric(monthly_df[x],downcast='float')\n\n    # Add year column to filter by\n    monthly_df['Year'] = list(map(lambda date: int(str(date)[0:4]), monthly_df.index)) # Create year column to filter out years prior to 2004\n    monthly_df = monthly_df[monthly_df['Year']>2005]\n\n    monthly_df = modern_df.join(monthly_df.drop(['Year'],axis=1),how='outer')\n    monthly_df.drop([\"open\",'high','low','close','volume','Year'],axis=1,inplace=True) \n    monthly_df['date'] = list(monthly_df.index)\n    monthly_df.reset_index(inplace=True)\n    monthly_df.drop('index',axis=1,inplace=True)\n    \n    # Save to blob container in JSON format\n    monthly_df.to_json(f\"/dbfs{mount_point}/Cleaned_Dataframes/monthly_data.json\")\nexcept Exception as e:\n    print(e)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6609c8c0-9b0b-4c63-b21d-8f2641d64a2b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n&lt;command-522247351784039&gt;:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  modern_df[column] = mean_fit.fit_transform(modern_df[column].values.reshape(-1,1)) # Ready to load into a SQL table\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Loading the Data Frames into our SQL Database:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"62e25248-7041-4338-858e-3d60d3fe2bf2"}}},{"cell_type":"code","source":["# Loading for ETL document\n\nserver=\"gen10-data-fundamentals-21-11-sql-server.database.windows.net\"\ndatabase=\"Super-Financial-Bros\"\nusername=dbutils.secrets.get(scope = 'sfb_blob', key = 'birdo') # Insert Username Here\npassword=dbutils.secrets.get(scope = 'sfb_blob', key = 'donkeykong') # Insert Password Here\n\nspark_annual_df = spark.createDataFrame(annual_df)\nspark_monthly_df = spark.createDataFrame(monthly_df)\n\nspark_annual_df.write.format('jdbc').option(\"url\", f\"jdbc:sqlserver://{server}:1433;databaseName={database};\") \\\n    .mode(\"overwrite\") \\\n    .option(\"dbtable\", \"annualData\") \\\n    .option(\"user\", username) \\\n    .option(\"password\", password) \\\n    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n    .save()\n\nspark_monthly_df.write.format('jdbc').option(\"url\", f\"jdbc:sqlserver://{server}:1433;databaseName={database};\") \\\n    .mode(\"overwrite\") \\\n    .option(\"dbtable\", \"monthlyData\") \\\n    .option(\"user\", username) \\\n    .option(\"password\", password) \\\n    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n    .save()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c68edbaf-5998-44a3-a90d-fcbbe43cc8da"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6436056b-d3ba-48d3-8452-13aba38bccfb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Base-Consumer","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":522247351783534}},"nbformat":4,"nbformat_minor":0}
